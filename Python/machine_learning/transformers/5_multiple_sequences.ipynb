{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4","authorship_tag":"ABX9TyOMeT213lD+WQG5TaUIQXcb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"28820bfbe3c146648338fab445e6c860":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_43d940f9b8614c88acaf88b002272dc0","IPY_MODEL_77b393864185472d992e90e90b24838a","IPY_MODEL_0cdf06fadc3e46fd91d7bf7951b485c3"],"layout":"IPY_MODEL_300fd7b621d34f8e9fc4f367929e0490"}},"43d940f9b8614c88acaf88b002272dc0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ceb6ff9db64d41ebbcb4766346c12091","placeholder":"​","style":"IPY_MODEL_9732a96b1d9b4319aefd04932225f72a","value":"tokenizer_config.json: 100%"}},"77b393864185472d992e90e90b24838a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9142678052c5417a9e96b212f644de4b","max":48,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7129f110dd9b435b9a7fdc83fdf1fa1e","value":48}},"0cdf06fadc3e46fd91d7bf7951b485c3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_15c9b4cccc084784ac21c704414d7387","placeholder":"​","style":"IPY_MODEL_f85211a221074071b427142aa2b3aca4","value":" 48.0/48.0 [00:00&lt;00:00, 3.30kB/s]"}},"300fd7b621d34f8e9fc4f367929e0490":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ceb6ff9db64d41ebbcb4766346c12091":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9732a96b1d9b4319aefd04932225f72a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9142678052c5417a9e96b212f644de4b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7129f110dd9b435b9a7fdc83fdf1fa1e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"15c9b4cccc084784ac21c704414d7387":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f85211a221074071b427142aa2b3aca4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ec56ddcb2f484d46a11f54cab5aa9654":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6873b7e60fe049f383255df7d16aa12d","IPY_MODEL_110ffa2269d642488a9c870e785e573c","IPY_MODEL_657c140935194c07a0d6b7f103545702"],"layout":"IPY_MODEL_ce528c813e9a47e0b54ab3d5f803c2a6"}},"6873b7e60fe049f383255df7d16aa12d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d72d456c589940a9a4b78331f07a4863","placeholder":"​","style":"IPY_MODEL_fb81f9e558614d0d9680bc9797dee827","value":"config.json: 100%"}},"110ffa2269d642488a9c870e785e573c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7652c268822c4054a9135bf7ffaa7289","max":629,"min":0,"orientation":"horizontal","style":"IPY_MODEL_29bcf18120e44f0ea09bc66634839eaf","value":629}},"657c140935194c07a0d6b7f103545702":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7dce2b232381453b8485bd2d30d3c94e","placeholder":"​","style":"IPY_MODEL_0de945c59a104aee8fedd440a8a235d5","value":" 629/629 [00:00&lt;00:00, 45.5kB/s]"}},"ce528c813e9a47e0b54ab3d5f803c2a6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d72d456c589940a9a4b78331f07a4863":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fb81f9e558614d0d9680bc9797dee827":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7652c268822c4054a9135bf7ffaa7289":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"29bcf18120e44f0ea09bc66634839eaf":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7dce2b232381453b8485bd2d30d3c94e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0de945c59a104aee8fedd440a8a235d5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"92ab47917f1d43c5bced942677032c29":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_40cf31a732e14d00948a8abe759db117","IPY_MODEL_c50b755692514d64b58f8af752b03d17","IPY_MODEL_b63614e390f54293ac68e3947aee5428"],"layout":"IPY_MODEL_a2689058170f4e5c9e2b294453935201"}},"40cf31a732e14d00948a8abe759db117":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_64d2862c69904fbba2fe294470818184","placeholder":"​","style":"IPY_MODEL_5af25ee8394643428cb9e58ab4b8a827","value":"vocab.txt: 100%"}},"c50b755692514d64b58f8af752b03d17":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9650470bbb2442fb9b212fa0704f99cd","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9e7322cc5f474b099e42ad7ae1224a5c","value":231508}},"b63614e390f54293ac68e3947aee5428":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a0571475950544ecb1f4856ed36e7937","placeholder":"​","style":"IPY_MODEL_b5280bc83b1e44f89a221cc1162a6410","value":" 232k/232k [00:00&lt;00:00, 11.6MB/s]"}},"a2689058170f4e5c9e2b294453935201":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"64d2862c69904fbba2fe294470818184":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5af25ee8394643428cb9e58ab4b8a827":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9650470bbb2442fb9b212fa0704f99cd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9e7322cc5f474b099e42ad7ae1224a5c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a0571475950544ecb1f4856ed36e7937":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b5280bc83b1e44f89a221cc1162a6410":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a628bd5f06a842268968bf04082fee11":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4e3195d08d6b4abd802807649b0b2765","IPY_MODEL_cc5743a3c19c4d729419406d8fe63021","IPY_MODEL_9f7e199923924c87afe385991d39f9b5"],"layout":"IPY_MODEL_4e13e711bd71440fbf8fc670544bd223"}},"4e3195d08d6b4abd802807649b0b2765":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_13afea95b7dd402e8c1dd37661df8e46","placeholder":"​","style":"IPY_MODEL_0f3d508f7fbe4e1288275e4ba13304ee","value":"model.safetensors: 100%"}},"cc5743a3c19c4d729419406d8fe63021":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f1041c4d915c4b20aa659fbd2306639b","max":267832558,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0ddd49f648524374b0059b1292cabca2","value":267832558}},"9f7e199923924c87afe385991d39f9b5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e26c76c27fee41ca9375d7a76384b6b4","placeholder":"​","style":"IPY_MODEL_1f9b239a4d0b4dbfbbaee43c2e272a10","value":" 268M/268M [00:00&lt;00:00, 397MB/s]"}},"4e13e711bd71440fbf8fc670544bd223":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"13afea95b7dd402e8c1dd37661df8e46":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0f3d508f7fbe4e1288275e4ba13304ee":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f1041c4d915c4b20aa659fbd2306639b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0ddd49f648524374b0059b1292cabca2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e26c76c27fee41ca9375d7a76384b6b4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1f9b239a4d0b4dbfbbaee43c2e272a10":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["Transformersで扱うモデルは基本的に同時に複数の文章(リスト)を入力として扱う。そのため、入力として期待されているのは２次元のtensorである。\n","\n","上記の理由から、下記のコードは1次元のtensorを入力していることから、Errorを返す。"],"metadata":{"id":"uceqXE9LE1l2"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"gTtGAAHhDRjf","executionInfo":{"status":"ok","timestamp":1710053914449,"user_tz":-540,"elapsed":6245,"user":{"displayName":"chinchilla","userId":"17621678834685835832"}}},"outputs":[],"source":["import torch\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification\n","\n","import pprint"]},{"cell_type":"code","source":["# 事前学習済のトークナイザとモデルを読み込む\n","ckpt = 'distilbert-base-uncased-finetuned-sst-2-english'\n","tokenizer = AutoTokenizer.from_pretrained(ckpt)\n","model = AutoModelForSequenceClassification.from_pretrained(ckpt)"],"metadata":{"id":"NkctHBVmHjBX","executionInfo":{"status":"ok","timestamp":1710053917313,"user_tz":-540,"elapsed":2871,"user":{"displayName":"chinchilla","userId":"17621678834685835832"}},"colab":{"base_uri":"https://localhost:8080/","height":252,"referenced_widgets":["28820bfbe3c146648338fab445e6c860","43d940f9b8614c88acaf88b002272dc0","77b393864185472d992e90e90b24838a","0cdf06fadc3e46fd91d7bf7951b485c3","300fd7b621d34f8e9fc4f367929e0490","ceb6ff9db64d41ebbcb4766346c12091","9732a96b1d9b4319aefd04932225f72a","9142678052c5417a9e96b212f644de4b","7129f110dd9b435b9a7fdc83fdf1fa1e","15c9b4cccc084784ac21c704414d7387","f85211a221074071b427142aa2b3aca4","ec56ddcb2f484d46a11f54cab5aa9654","6873b7e60fe049f383255df7d16aa12d","110ffa2269d642488a9c870e785e573c","657c140935194c07a0d6b7f103545702","ce528c813e9a47e0b54ab3d5f803c2a6","d72d456c589940a9a4b78331f07a4863","fb81f9e558614d0d9680bc9797dee827","7652c268822c4054a9135bf7ffaa7289","29bcf18120e44f0ea09bc66634839eaf","7dce2b232381453b8485bd2d30d3c94e","0de945c59a104aee8fedd440a8a235d5","92ab47917f1d43c5bced942677032c29","40cf31a732e14d00948a8abe759db117","c50b755692514d64b58f8af752b03d17","b63614e390f54293ac68e3947aee5428","a2689058170f4e5c9e2b294453935201","64d2862c69904fbba2fe294470818184","5af25ee8394643428cb9e58ab4b8a827","9650470bbb2442fb9b212fa0704f99cd","9e7322cc5f474b099e42ad7ae1224a5c","a0571475950544ecb1f4856ed36e7937","b5280bc83b1e44f89a221cc1162a6410","a628bd5f06a842268968bf04082fee11","4e3195d08d6b4abd802807649b0b2765","cc5743a3c19c4d729419406d8fe63021","9f7e199923924c87afe385991d39f9b5","4e13e711bd71440fbf8fc670544bd223","13afea95b7dd402e8c1dd37661df8e46","0f3d508f7fbe4e1288275e4ba13304ee","f1041c4d915c4b20aa659fbd2306639b","0ddd49f648524374b0059b1292cabca2","e26c76c27fee41ca9375d7a76384b6b4","1f9b239a4d0b4dbfbbaee43c2e272a10"]},"outputId":"834945fb-d33e-4ae8-ca9a-e00921044a57"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"28820bfbe3c146648338fab445e6c860"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec56ddcb2f484d46a11f54cab5aa9654"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"92ab47917f1d43c5bced942677032c29"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a628bd5f06a842268968bf04082fee11"}},"metadata":{}}]},{"cell_type":"code","source":["# 単一の文章をそのままid列に変換\n","sentence = 'Saito is so popular with girls.'\n","tokens = tokenizer.tokenize(sentence)\n","ids = tokenizer.convert_tokens_to_ids(tokens)\n","bad_input_ids = torch.tensor(ids)\n","\n","pprint.pprint(bad_input_ids)\n","print(f'Dimensions: {bad_input_ids.ndim}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"90rD4vWRHOQL","executionInfo":{"status":"ok","timestamp":1710053917722,"user_tz":-540,"elapsed":416,"user":{"displayName":"chinchilla","userId":"17621678834685835832"}},"outputId":"066ebe04-0c3d-4c19-fe07-04c32fabe2a8"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([18952,  3406,  2003,  2061,  2759,  2007,  3057,  1012])\n","Dimensions: 1\n"]}]},{"cell_type":"code","source":["# ここでErrorになる。\n","model(bad_input_ids)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":311},"id":"7A6vnEdRG4DA","executionInfo":{"status":"error","timestamp":1710053918025,"user_tz":-540,"elapsed":310,"user":{"displayName":"chinchilla","userId":"17621678834685835832"}},"outputId":"10de106f-9045-4083-ba43-1ffd7b57d7cc"},"execution_count":4,"outputs":[{"output_type":"error","ename":"IndexError","evalue":"too many indices for tensor of dimension 1","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-f380432746b2>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# ここでErrorになる。\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbad_input_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/distilbert/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1000\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1002\u001b[0;31m         distilbert_output = self.distilbert(\n\u001b[0m\u001b[1;32m   1003\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/distilbert/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    800\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You cannot specify both input_ids and inputs_embeds at the same time\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0minput_ids\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 802\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn_if_padding_and_no_attention_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    803\u001b[0m             \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    804\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mwarn_if_padding_and_no_attention_mask\u001b[0;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[1;32m   4167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4168\u001b[0m         \u001b[0;31m# Check only the first and last input IDs to reduce overhead.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4169\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_token_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4170\u001b[0m             warn_string = (\n\u001b[1;32m   4171\u001b[0m                 \u001b[0;34m\"We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 1"]}]},{"cell_type":"markdown","source":["このErrorはmodelへの入力を期待されている2次元のtensorへ変換することで解消できる。"],"metadata":{"id":"ZYtDQGoRDPwG"}},{"cell_type":"code","source":["# id列を2次元のtensorに変換\n","input_ids = torch.tensor([ids])\n","\n","pprint.pprint(input_ids)\n","print(f'Dimensions: {input_ids.ndim}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iZOv3Ya8KiUB","executionInfo":{"status":"ok","timestamp":1710053925790,"user_tz":-540,"elapsed":347,"user":{"displayName":"chinchilla","userId":"17621678834685835832"}},"outputId":"6fab9369-befd-4661-941a-9a87b1279e65"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[18952,  3406,  2003,  2061,  2759,  2007,  3057,  1012]])\n","Dimensions: 2\n"]}]},{"cell_type":"code","source":["# unsqueeze()を使っても次元拡張ができる\n","## https://pytorch.org/docs/stable/generated/torch.unsqueeze.html#torch.unsqueeze\n","input_ids = bad_input_ids.unsqueeze(0)\n","\n","pprint.pprint(input_ids)\n","print(f'Dimensions: {input_ids.ndim}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"akvhu6XfyZVi","executionInfo":{"status":"ok","timestamp":1710053926602,"user_tz":-540,"elapsed":3,"user":{"displayName":"chinchilla","userId":"17621678834685835832"}},"outputId":"b768e4e5-b3a6-41b0-93c4-6873afb8dc4a"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[18952,  3406,  2003,  2061,  2759,  2007,  3057,  1012]])\n","Dimensions: 2\n"]}]},{"cell_type":"code","source":["out = model(input_ids).logits\n","out"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AieI2W7IK93s","executionInfo":{"status":"ok","timestamp":1710053927353,"user_tz":-540,"elapsed":3,"user":{"displayName":"chinchilla","userId":"17621678834685835832"}},"outputId":"4ca64bf5-2ddd-4905-dcf0-4923c38c1aed"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[-2.1485,  2.1525]], grad_fn=<AddmmBackward0>)"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["import torch.nn.functional as F\n","\n","F.softmax(out, dim=-1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wxJc02rsK_At","executionInfo":{"status":"ok","timestamp":1710053927771,"user_tz":-540,"elapsed":3,"user":{"displayName":"chinchilla","userId":"17621678834685835832"}},"outputId":"86db1b7c-9484-4511-b36d-8dbd384619b4"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0.0134, 0.9866]], grad_fn=<SoftmaxBackward0>)"]},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","source":["また、tokenizerそのものを使った時の出力も確認してみると、以下のようになる。"],"metadata":{"id":"NnGW1-L4hgb0"}},{"cell_type":"code","source":["tokenized_input = tokenizer(sentence, return_tensors='pt')\n","tokenized_input['input_ids']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pc_AoMJxhGxG","executionInfo":{"status":"ok","timestamp":1710053932398,"user_tz":-540,"elapsed":4,"user":{"displayName":"chinchilla","userId":"17621678834685835832"}},"outputId":"b4809cb2-3fc7-4965-f343-7a6f509bd721"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[  101, 18952,  3406,  2003,  2061,  2759,  2007,  3057,  1012,   102]])"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","source":["これは先ほどのinput_idsと同じ次元をもつtensorを返し、かつ初頭と終端に`[CLS]`と`[SEP]`という特殊トークンを挿入している事に注意する。"],"metadata":{"id":"7ctLKZphiAhh"}},{"cell_type":"markdown","source":["続いて、入力を複数の文章(リスト)としてmodelに入力するまでの処理を考える。\n","仮にトークナイズ・id化済みのid列が下記のように得られたとする。\n","\n"],"metadata":{"id":"dFZrpcJWECEr"}},{"cell_type":"code","source":["batched_ids = [\n","    [100],\n","    [200, 200],\n","    [300, 300, 300],\n","]"],"metadata":{"id":"zJoMnXqDF0RC","executionInfo":{"status":"ok","timestamp":1710053935667,"user_tz":-540,"elapsed":22,"user":{"displayName":"chinchilla","userId":"17621678834685835832"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["これをそのままtensorに変換しようとすると下記のようにエラーになる。\n","これはtensorはリストの各要素(文章)の長さが等しい事を前提としている事が理由である。"],"metadata":{"id":"yjPNt9Sr0Rnk"}},{"cell_type":"code","source":["torch.tensor(batched_ids)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":144},"id":"V6RXP1st0RVt","executionInfo":{"status":"error","timestamp":1710053938313,"user_tz":-540,"elapsed":27,"user":{"displayName":"chinchilla","userId":"17621678834685835832"}},"outputId":"d6b09acc-3aa3-43b3-9e4d-1e7016e197b1"},"execution_count":11,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"expected sequence of length 1 at dim 1 (got 2)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-9067f8a1107c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatched_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mValueError\u001b[0m: expected sequence of length 1 at dim 1 (got 2)"]}]},{"cell_type":"markdown","source":["そこで、複数の文章をmodelに入力するには工夫をする必要があり、その一つがpaddingである。\n","\n","paddingとは、特殊トークンを使ってid列の長さをそろえることである。"],"metadata":{"id":"gN2Qy2Z61XAt"}},{"cell_type":"code","source":["padding_id = tokenizer.pad_token_id\n","\n","batched_ids = [\n","    [200, padding_id, padding_id],\n","    [200, 200, padding_id],\n","    [200, 200, 200],\n","]\n","\n","torch.tensor(batched_ids)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GmNU1jTK1FLq","executionInfo":{"status":"ok","timestamp":1710053943039,"user_tz":-540,"elapsed":8,"user":{"displayName":"chinchilla","userId":"17621678834685835832"}},"outputId":"5da954ad-952c-4981-96da-6e8c4d7c2203"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[200,   0,   0],\n","        [200, 200,   0],\n","        [200, 200, 200]])"]},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","source":["ちなみに、上記の例の場合、`padding_id`は`[PAD]`というトークンを表している。"],"metadata":{"id":"XzTG0XHIGCTe"}},{"cell_type":"code","source":["tokenizer.decode(batched_ids[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"xGIYWZ2H2OUa","executionInfo":{"status":"ok","timestamp":1710053956161,"user_tz":-540,"elapsed":269,"user":{"displayName":"chinchilla","userId":"17621678834685835832"}},"outputId":"ab1bd09f-5000-4506-e0f4-7f75af79de2b"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'[unused195] [PAD] [PAD]'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","source":["続いて、このid列を入力としたときの出力を確認する。"],"metadata":{"id":"-ISFI7rpHVoo"}},{"cell_type":"code","source":["no_pad_tensor = torch.tensor([[200, 200]])\n","pad_tensor = torch.tensor([[200, 200, padding_id]])\n","\n","batched_ids_tensor = torch.tensor(batched_ids)\n","\n","# paddingなし/ありで出力は変わって欲しく無い。\n","pprint.pprint(model(no_pad_tensor).logits)  # paddingなし\n","pprint.pprint(model(pad_tensor).logits)      # paddingあり\n","\n","pprint.pprint(model(batched_ids_tensor).logits)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oYCOGjuuGPj8","executionInfo":{"status":"ok","timestamp":1710053959239,"user_tz":-540,"elapsed":506,"user":{"displayName":"chinchilla","userId":"17621678834685835832"}},"outputId":"616acbf2-aaab-47fb-de23-196f5f070a4a"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stderr","text":["We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n"]},{"output_type":"stream","name":"stdout","text":["tensor([[ 0.5803, -0.4125]], grad_fn=<AddmmBackward0>)\n","tensor([[ 1.3374, -1.2163]], grad_fn=<AddmmBackward0>)\n","tensor([[ 1.0182, -0.9527],\n","        [ 1.3374, -1.2163],\n","        [ 1.5694, -1.3895]], grad_fn=<AddmmBackward0>)\n"]}]},{"cell_type":"markdown","source":["このとき、[PAD]トークンの有無によって出力が異なると実用上好ましくない(文意が一緒なのに、出力が異なるため)が、上の例では、paddingの有無によって出力が異なってしまっている。\n","\n","そこで、tokenizerでは通常自動でattention_maskを付加する事で、[PAD]トークンをAttention機構の計算過程で無視するという仕組みを実現している。\n","\n","同様の処理を行うため、先ほどのbatched_idsでpadding_idを挿入した位置に着目してattention_maskを作る。"],"metadata":{"id":"302FLhCNI2xv"}},{"cell_type":"code","source":["attention_mask = torch.tensor(\n","    [\n","        [1, 0, 0],\n","        [1, 1, 0],\n","        [1, 1, 1]\n","    ]\n",")\n","\n","outputs = model(batched_ids_tensor, attention_mask=attention_mask)\n","\n","pprint.pprint(outputs.logits)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-H12n2W8MJqb","executionInfo":{"status":"ok","timestamp":1710053961455,"user_tz":-540,"elapsed":281,"user":{"displayName":"chinchilla","userId":"17621678834685835832"}},"outputId":"f088b4b5-68ec-4428-8647-98183ad719b0"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[-0.6815,  0.9039],\n","        [ 0.5803, -0.4125],\n","        [ 1.5694, -1.3895]], grad_fn=<AddmmBackward0>)\n"]}]},{"cell_type":"markdown","source":["ここで注目すべきは、attention_maskを入力した事でoutput.logits[1]とmodel(no_pad_tensor).logitsが一致する事である。\n","\n","これらの処理を踏まえて、tokenizerそのもので文章のリストを変換した時の出力を確認すると、以下のようになる。"],"metadata":{"id":"dPH1PTXiNKfP"}},{"cell_type":"code","source":["sentences = [\n","    'I love you.',\n","    'I love you, too.',\n","    'I am loving hamburger and fries.',\n","]\n","\n","pprint.pprint(tokenizer(sentences,  padding='longest', return_tensors='pt'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F-0VJrEIIh27","executionInfo":{"status":"ok","timestamp":1710054585070,"user_tz":-540,"elapsed":717,"user":{"displayName":"chinchilla","userId":"17621678834685835832"}},"outputId":"bc7a25f1-e72a-42d8-b87a-b40793b51a3b"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["{'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 0, 0, 0],\n","        [1, 1, 1, 1, 1, 1, 1, 1, 0],\n","        [1, 1, 1, 1, 1, 1, 1, 1, 1]]),\n"," 'input_ids': tensor([[  101,  1045,  2293,  2017,  1012,   102,     0,     0,     0],\n","        [  101,  1045,  2293,  2017,  1010,  2205,  1012,   102,     0],\n","        [  101,  1045,  2572,  8295, 24575,  1998, 22201,  1012,   102]])}\n"]}]},{"cell_type":"markdown","source":["この処理で確認できるように、tokenizerによって文章のリストを変換した際には、paddingによってリスト長の揃ったid列と同時に、[PAD]トークンの位置に０を持つattention_maskを出力している事がわかる。\n","この時、paddingは`longest`と指定している事に注意する。"],"metadata":{"id":"FC5El2wLMzT6"}},{"cell_type":"markdown","source":["最後に、長い文章を入力とする事を考える。\n","通常のhuggingfaceのBertモデルは最大token長512または１０２４としている事が多く、これを超える入力を与えるとエラーとなる。\n","\n","そこで、より長い文章を扱うには、\n","\n","\n","1.   長い文章を入力可能なモデルを使う\n","2.   入力文を切り詰める(truncation)\n","\n","のいずれかを選択する必要がある。\n","tokenizerで選択肢２を行うためには、引数の`truncation=True`を指定する事で実現できる。"],"metadata":{"id":"G9lGGh2QN73t"}},{"cell_type":"code","source":[],"metadata":{"id":"NqId02i5LoSF"},"execution_count":null,"outputs":[]}]}