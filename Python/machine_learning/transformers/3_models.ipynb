{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMmVbQQhY8TMyYdY085NA+q"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 環境設定"],"metadata":{"id":"UW-zOBKz_TCl"}},{"cell_type":"code","source":["import os\n","import sys\n","\n","def _is_in_kaggle() -> bool:\n","  \"\"\"Whether the current environment is in `Kaggle`.\"\"\"\n","  return str(_dh[0]) == '/kaggle/working'\n","\n","\n","def _is_in_colab() -> bool:\n","  \"\"\"Whether the current environment is in `Colab`.\"\"\"\n","  return 'google.colab' in str(get_ipython())"],"metadata":{"id":"BABU_Pa7jxxI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if _is_in_kaggle():\n","  print('in kaggle')\n","\n","elif _is_in_colab():\n","  print('in colab')\n","  from google.colab import drive\n","  drive.mount('/content/drive')  # mount google drive\n","  DRIVE_ROOT = '/content/drive/MyDrive'\n","  sys.path.append('/content/drive/MyDrive/Colab Notebooks/my-modules')  # path from drive\n","\n","else:\n","  print('in local')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4Q-J4MNokEdx","executionInfo":{"status":"ok","timestamp":1709371154477,"user_tz":-540,"elapsed":4802,"user":{"displayName":"chinchilla","userId":"17621678834685835832"}},"outputId":"8887c4c7-207c-47c2-f296-7774eed5b6a9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["in colab\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["# Modelの扱い"],"metadata":{"id":"6RvNn2_UWd0X"}},{"cell_type":"markdown","source":["## scratchでのBert読み込み"],"metadata":{"id":"D0BJb1cLWjys"}},{"cell_type":"markdown","source":["Bertを例にTransformersでのModelの構築を行う。\n","まずはscratchでBertを学習させるという仮定のもとModelを呼び出す。"],"metadata":{"id":"vZq7X4rcFxUe"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"mfdW9_Nh5eey"},"outputs":[],"source":["from transformers import BertConfig, BertModel, BertTokenizer\n","\n","# Configを使ったモデル呼び出し\n","config = BertConfig()\n","model = BertModel(config)"]},{"cell_type":"code","source":["# BertConfigには、BERTのネットワークを構成する為のパラメータが含まれている。\n","print(config)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Si61Q6PrGLPr","executionInfo":{"status":"ok","timestamp":1709371157179,"user_tz":-540,"elapsed":8,"user":{"displayName":"chinchilla","userId":"17621678834685835832"}},"outputId":"cf6ca369-6fa9-4bf9-9fa4-baf8ec3f7830"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["BertConfig {\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.38.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 30522\n","}\n","\n"]}]},{"cell_type":"code","source":["# BertModelのネットワーク詳細を表示\n","print(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ePH5NtnDGPi4","executionInfo":{"status":"ok","timestamp":1709371157179,"user_tz":-540,"elapsed":7,"user":{"displayName":"chinchilla","userId":"17621678834685835832"}},"outputId":"e1ce5040-6d3f-46ca-c887-3f3494d8a45a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["BertModel(\n","  (embeddings): BertEmbeddings(\n","    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","    (position_embeddings): Embedding(512, 768)\n","    (token_type_embeddings): Embedding(2, 768)\n","    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (encoder): BertEncoder(\n","    (layer): ModuleList(\n","      (0-11): 12 x BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          (intermediate_act_fn): GELUActivation()\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","  )\n","  (pooler): BertPooler(\n","    (dense): Linear(in_features=768, out_features=768, bias=True)\n","    (activation): Tanh()\n","  )\n",")\n"]}]},{"cell_type":"markdown","source":["このModelを学習させることにより、BERTを１から作ることができるが、これは非常に大きな計算リソースと時間を要することになり、無謀である。\n","\n","そこで、既に学習済みのBERTモデルを呼び出し、このモデルを使うことで短時間にかつ安価に有用なモデルを作成することができる。"],"metadata":{"id":"i2lC6TNybM6J"}},{"cell_type":"markdown","source":["## 学習済みモデルの呼び出し"],"metadata":{"id":"THfaLz47Wwve"}},{"cell_type":"code","source":["model = BertModel.from_pretrained(\"bert-base-uncased\")"],"metadata":{"id":"Dd_37vWoGmNy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## モデルの保存"],"metadata":{"id":"9bbnsyowW3M7"}},{"cell_type":"markdown","source":["作成したモデルを保存することもできる。"],"metadata":{"id":"ZOzjORJ-QDtZ"}},{"cell_type":"code","source":["# モデルを保存\n","model.save_pretrained(\"./bert_model\")"],"metadata":{"id":"gWCoaIoBJMmI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# configとモデルの重みが保存されている\n","ls ./bert_model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":108},"id":"oRGzanukSzga","executionInfo":{"status":"error","timestamp":1709371185351,"user_tz":-540,"elapsed":258,"user":{"displayName":"chinchilla","userId":"17621678834685835832"}},"outputId":"f87b5c76-5df2-4e2e-ffd8-e8cf276a507e"},"execution_count":null,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"invalid syntax (<ipython-input-45-b6125a41d908>, line 2)","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-45-b6125a41d908>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    ls \"./bert_model\"\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}]},{"cell_type":"code","source":["# 保存したモデルを読み込む\n","model_saved = BertModel.from_pretrained(\"./bert_model\")\n","model_saved"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ebm0pMZpQaC1","executionInfo":{"status":"ok","timestamp":1709371195910,"user_tz":-540,"elapsed":675,"user":{"displayName":"chinchilla","userId":"17621678834685835832"}},"outputId":"2397d787-ed60-4f34-faa0-9ef32dec47ef"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BertModel(\n","  (embeddings): BertEmbeddings(\n","    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","    (position_embeddings): Embedding(512, 768)\n","    (token_type_embeddings): Embedding(2, 768)\n","    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (encoder): BertEncoder(\n","    (layer): ModuleList(\n","      (0-11): 12 x BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          (intermediate_act_fn): GELUActivation()\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","  )\n","  (pooler): BertPooler(\n","    (dense): Linear(in_features=768, out_features=768, bias=True)\n","    (activation): Tanh()\n","  )\n",")"]},"metadata":{},"execution_count":46}]},{"cell_type":"markdown","source":["# 推論"],"metadata":{"id":"jtAstLodWXa0"}},{"cell_type":"markdown","source":["機械学習モデルとは、つまるところテンソル(数字の配列や行列など)を入出力とする関数の近似である。\n","そのため、機械学習モデルの入力はテンソルである必要があると言える。\n","\n","Bertも同様で、入力となる文字列(のリスト)はTokenizerによりテンソルに変換して初めてBertに渡すことができる。"],"metadata":{"id":"reRmwayiYJ84"}},{"cell_type":"code","source":["sequences = [\"Hello!\", \"Cool.\", \"Nice!\"]"],"metadata":{"id":"22cTLBBYYIDj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# tokenizerを使って、文字列をID列に変換\n","tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n","encoded_sequences = tokenizer(sequences).input_ids  # 通常はinput_idsのみを入力することは無いが、ここでは説明のため\n","encoded_sequences"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KBrY7grXbHmb","executionInfo":{"status":"ok","timestamp":1709371309383,"user_tz":-540,"elapsed":268,"user":{"displayName":"chinchilla","userId":"17621678834685835832"}},"outputId":"c38105f0-c7df-49d2-df4b-0760d2ad4e2c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[101, 7592, 999, 102], [101, 4658, 1012, 102], [101, 3835, 999, 102]]"]},"metadata":{},"execution_count":59}]},{"cell_type":"code","source":["# modelへの入力はtensorである必要がある\n","import torch\n","model_inputs = torch.tensor(encoded_sequences)"],"metadata":{"id":"cwc6HeS_bWe8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#modelへ入力\n","model(model_inputs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hg5o2eS_b3pq","executionInfo":{"status":"ok","timestamp":1709371376321,"user_tz":-540,"elapsed":1372,"user":{"displayName":"chinchilla","userId":"17621678834685835832"}},"outputId":"eb91c2d0-c477-4b80-add1-723de4183065"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-5.0937e-02,  1.0882e-01, -1.4107e-01,  ..., -1.2431e-01,\n","          -8.0330e-02,  2.8579e-01],\n","         [-6.7714e-01, -5.4644e-01,  8.7821e-02,  ..., -5.7526e-02,\n","           3.5945e-02, -3.0803e-01],\n","         [-1.0903e+00, -9.9962e-01, -5.6360e-01,  ...,  3.2317e-01,\n","          -2.7725e-01, -1.4627e-01],\n","         [ 8.3018e-01,  5.0071e-02, -2.2515e-01,  ...,  3.2161e-01,\n","          -6.4891e-01, -2.4565e-01]],\n","\n","        [[-2.8582e-01, -1.8635e-02,  7.9945e-02,  ..., -3.2150e-01,\n","           3.1830e-01,  5.7760e-01],\n","         [ 4.5425e-01, -5.5394e-01,  3.9479e-01,  ..., -2.2183e-01,\n","           1.8811e-01,  1.0380e-01],\n","         [-2.7685e-01, -1.0924e+00,  2.2841e-01,  ...,  2.6004e-01,\n","           3.7289e-01,  6.6872e-02],\n","         [ 9.7986e-01, -2.8927e-02, -1.4129e-01,  ...,  3.6114e-01,\n","          -6.3582e-01, -1.5223e-01]],\n","\n","        [[-7.1083e-04,  1.6308e-01, -1.2003e-01,  ..., -1.5940e-02,\n","          -5.3252e-02,  3.6561e-01],\n","         [ 2.2237e-01, -2.5055e-01,  1.4829e-01,  ..., -2.5916e-01,\n","          -1.1177e-01, -3.8677e-01],\n","         [-4.5976e-01, -6.7149e-01, -6.2246e-01,  ...,  7.8526e-01,\n","          -6.2649e-02,  2.0197e-01],\n","         [ 8.8013e-01,  1.0413e-01, -3.6112e-01,  ...,  2.0877e-01,\n","          -7.1188e-01, -1.6407e-01]]], grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-0.7559, -0.1365,  0.3615,  ...,  0.2424, -0.4873,  0.8204],\n","        [-0.9467, -0.3791, -0.9621,  ..., -0.8796, -0.6450,  0.9321],\n","        [-0.7808, -0.1918,  0.4011,  ...,  0.2313, -0.5427,  0.8336]],\n","       grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"]},"metadata":{},"execution_count":63}]},{"cell_type":"code","source":[],"metadata":{"id":"BYk8u_4beOjo"},"execution_count":null,"outputs":[]}]}