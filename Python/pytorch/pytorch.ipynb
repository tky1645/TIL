{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch とは\n",
    "\n",
    "オブジェクト指向型の深層学習ライブラリ。\n",
    "テンソル計算と自動微分をサポートするフレームワークで、PyTorch ではこれを使って機械学習のモデルやアルゴリズムを構築する。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# Utilities\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ネットワークの作成\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nn.Sequential を使った書き方\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=3, out_features=8, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=8, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ランダムシードの設定\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# 簡単なネットワークの設定\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(3, 8),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(8, 1)\n",
    ")\n",
    "\n",
    "# ネットワーク構成の確認\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param_0:, ('0.weight', Parameter containing:\n",
      "tensor([[ 0.4414,  0.4792, -0.1353],\n",
      "        [ 0.5304, -0.1265,  0.1165],\n",
      "        [-0.2811,  0.3391,  0.5090],\n",
      "        [-0.4236,  0.5018,  0.1081],\n",
      "        [ 0.4266,  0.0782,  0.2784],\n",
      "        [-0.0815,  0.4451,  0.0853],\n",
      "        [-0.2695,  0.1472, -0.2660],\n",
      "        [-0.0677, -0.2345,  0.3830]], requires_grad=True))\n",
      "param_1:, ('0.bias', Parameter containing:\n",
      "tensor([-0.4557, -0.2662, -0.1630, -0.3471,  0.0545, -0.5702,  0.5214, -0.4904],\n",
      "       requires_grad=True))\n",
      "param_2:, ('2.weight', Parameter containing:\n",
      "tensor([[ 0.2730,  0.0588, -0.1148,  0.2185,  0.0551,  0.2857,  0.0387, -0.1115]],\n",
      "       requires_grad=True))\n",
      "param_3:, ('2.bias', Parameter containing:\n",
      "tensor([0.0950], requires_grad=True))\n"
     ]
    }
   ],
   "source": [
    "# ネットワークのパラメータの確認\n",
    "for idx, param in enumerate(model.named_parameters()):  # named_parameters()メソッドはmodelのパラメータを返すgenerator\n",
    "  print(f'param_{idx}:, {param}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## カスタムレイヤーについて\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nn.Module を継承することで OOP に基づいたネットワーク層の記述ができる。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleClassification(nn.Module):\n",
    "  \"\"\"\n",
    "  Simple classification model consists of two layers with ReLU.\n",
    "  The input size can be changed and the output size is 3.\n",
    "  \"\"\"\n",
    "  def __init__(self, n_in):\n",
    "    super().__init__()\n",
    "    # 一層目の定義\n",
    "    self.layer1 = nn.Sequential(\n",
    "      nn.Linear(n_in, 10),\n",
    "      nn.ReLU()\n",
    "    )\n",
    "    # 二層目の定義\n",
    "    self.layer2 = nn.Sequential(\n",
    "      nn.Linear(10, 10),\n",
    "      nn.ReLU()\n",
    "    )\n",
    "    \n",
    "    # 三層目の定義\n",
    "    self.layer3 = nn.Sequential(\n",
    "      nn.Linear(10, 3),\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.layer1(x)\n",
    "    x = self.layer2(x)\n",
    "    out = self.layer3(x)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3])\n"
     ]
    }
   ],
   "source": [
    "# 入出力の確認\n",
    "torch.manual_seed(123)\n",
    "input = torch.randn(1, 3)\n",
    "\n",
    "model = SimpleClassification(n_in=len(input[0]))\n",
    "output = model(input)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## なぜ forward メソッドで予測ができるのか\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python では、クラスに特殊メソッド**call**を定義する事でクラスを関数のように使う事ができる。\n",
    "上記のカスタムクラスで継承している親クラス torch.nn.Module ではこの**call**メソッドを定義しており、その中で forward メソッドが呼ばれる事で処理が走っている。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 誤差逆伝播\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 誤差逆伝播とは\n",
    "\n",
    "ニューラルネットワークの学習とは、お手本となる教師データを使ってネットワークのパラメータを調整することである。その過程で出力と教師データの誤差を算出し、その勾配を使ってパラメータを更新する。\n",
    "\n",
    "その際、出力から入力の方向へ更新が進められるためこの方法を誤差逆伝播と呼ぶ。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iris データセットの読み込み\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.25 ,random_state=0)\n",
    "\n",
    "x = torch.tensor(X_train,dtype = torch.float)\n",
    "y = torch.tensor(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習のサイクル\n",
    "\n",
    "学習過程では、model(input)の出力を output とすると、まず損失関数 criterion(output)を計算する(loss)。\n",
    "この loss から勾配を計算し、optimizer で指定した最適化手法のもと誤差逆伝播を行いパラメータを更新する。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習モデルのインスタンスを作成\n",
    "model = SimpleClassification(X_train.shape[1])\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "# 損失関数の定義\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 1.0081254243850708\n",
      "loss : 0.8493548631668091\n",
      "loss : 0.7042444944381714\n",
      "loss : 0.5836213231086731\n",
      "loss : 0.48427101969718933\n",
      "loss : 0.4180900454521179\n",
      "loss : 0.3666849434375763\n",
      "loss : 0.31534937024116516\n",
      "loss : 0.26163241267204285\n"
     ]
    }
   ],
   "source": [
    "# 学習ループ\n",
    "epochs = 10\n",
    "iters = len(x)\n",
    "for epoch in range(1, epochs):\n",
    "    for i in range(1, iters):\n",
    "        # 勾配の初期化\n",
    "        optimizer.zero_grad()\n",
    "        # 説明変数xをネットワークにかける\n",
    "        output = model(x)\n",
    "        # 損失関数の計算\n",
    "        loss = criterion(output, y)\n",
    "        # 勾配の計算 \n",
    "        loss.backward()\n",
    "        # パラメタの更新\n",
    "        optimizer.step()\n",
    "\n",
    "        if i == len(x)-1:  # 1epochごとにloss表示\n",
    "            print(f\"loss : {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 94.7%\n"
     ]
    }
   ],
   "source": [
    "# 推論評価\n",
    "outputs = model(torch.tensor(X_test, dtype = torch.float))\n",
    "_, predicted = torch.max(outputs.data, 1)\n",
    "y_predicted = predicted.numpy()\n",
    "accuracy = 100 * np.sum(predicted.numpy() == y_test) / len(y_predicted)\n",
    "print('accuracy: {:.1f}%'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "また、今回はループをシンプルなものにしたが、通常はミニバッチ学習という手法を使う。\n",
    "ミニバッチ学習では学習データを任意の小さなまとまり(ミニバッチ)に分割し、このまとまりを 1 単位(1iteration)としてパラメータ更新を行う。\n",
    "ちなみに、データセット全てを 1 セットとして見たときに何セット学習したかを epoch 数(学習回数)と呼ぶ\n",
    "\n",
    "[参考資料](https://zenn.dev/nekoallergy/articles/ml-basic-epoch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの扱いについて\n",
    "\n",
    "データの前処理とバッチ処理は、PyTorch でニューラルネットワークモデルを訓練する際の重要なステップである。\n",
    "\n",
    "このプロセスを効率化し、柔軟性を提供するために、PyTorch は torch.utils.data.Dataset と torch.utils.data.DataLoader の 2 つの強力なクラスを提供している。これらを使用することで、大規模なデータセットを扱いやすくし、訓練プロセスを効率的に行うことができる。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset クラス\n",
    "\n",
    "特徴量行列（ラベル以外のデータ）X とラベル y を TensorDataset というクラスに渡して、特徴量行列とラベルを一つのデータベース的なものにまとめる事ができる。\n",
    "PyTorch では、この形式で Data を扱うのが基本となる。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pandas から TensorDataset へ変換\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Iris\n",
    "import seaborn as sns\n",
    "iris = sns.load_dataset('iris')\n",
    "print(type(iris))  # Pandasで読込まれている事の確認\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# カテゴリ変数を変換\n",
    "iris.loc[:, 'species'] = iris.loc[:, 'species'].map({'setosa':0, 'versicolor':1, 'virginica':2})\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pandas -> Numpy -> Tensor\n",
    "\n",
    "Pandas データセットは、直接データセットに変更できないので、Pandas を Numpy 配列に変換してから Dataset 型に変換を行う\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numpy変換の為にvaluesというメソッドを使用\n",
    "\n",
    "X = torch.FloatTensor(iris.drop(\"species\", axis=1).values)\n",
    "y = torch.LongTensor(iris[\"species\"].values.astype(np.int64))  # dtypeをint64へ変換してから処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasetを作成\n",
    "Dataset = torch.utils.data.TensorDataset(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 結果を確認\n",
    "X_sample, y_sample = Dataset[100]\n",
    "print(X_sample, y_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここまでが、基本的な Dataset の作成方法となる。\n",
    "一方でこのような Dataset の扱い方は現場ではほとんどの場合なく、もっと便利な自作（カスタム）Dataset というものを作成する。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### カスタム Dataset について\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dataset の設定\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "自作 Dataset を使用することで、前処理（Transformer）等を細かくカスタマイズすることができる。\n",
    "作成の際は以下の 3 点を設定する。\n",
    "\n",
    "1. torch.utils.data.Dataset クラスを継承\n",
    "2. 特殊メソッド**len**()の設定\n",
    "3. 特殊メソッド**getitem**()の設定\n",
    "\n",
    "以下、実際にカスタム Dataset の定義を行う。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[参考](../OOP.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IrisDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, features: list[str], labels: list[str]):\n",
    "        self.features = df[features].values\n",
    "        self.labels = df[labels].values.astype(np.int64)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        feature = torch.FloatTensor(self.features[idx])\n",
    "        label = torch.LongTensor(self.labels[idx])\n",
    "        return feature, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# インスタンス化\n",
    "iris_dataset = IrisDataset(iris, ['sepal_length', 'sepal_width', 'petal_length', 'petal_width'], ['species'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __len__メソッドの確認\n",
    "len(iris_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# __getitem__メソッドの確認\n",
    "iris_dataset[100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 前処理の追加\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "任意の処理を施す為の\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
